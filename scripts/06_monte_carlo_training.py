#!/usr/bin/env python3
"""
Script 06: DeepTCR Monte Carlo Cross-Validation Training
=========================================================

This script corresponds to Cell 87 (the final training cell) of the Untitled1.ipynb notebook.

PURPOSE:
--------
This is the MAIN TRAINING SCRIPT that implements 100-fold Monte Carlo Cross-Validation
using the DeepTCR framework to predict immunotherapy response from TCR repertoires.

WHAT IS MONTE CARLO CROSS-VALIDATION?
--------------------------------------
Instead of a single train/test split (which could be lucky or unlucky), Monte Carlo CV:
1. Randomly splits data into train/test sets (e.g., 75%/25%)
2. Trains a new model on this split
3. Evaluates on the test set
4. Repeats this process N times (N=100 in our case)
5. Final performance = average across all 100 folds

Benefits:
- More robust estimate of model performance
- Reduces variance from single split
- Tests generalization across many random scenarios
- Standard practice for medical ML applications

DEEP LEARNING ARCHITECTURE:
---------------------------
DeepTCR implements:
1. **Embedding Layer**: Converts sequences ‚Üí dense 128-D vectors
2. **Attention Mechanism**: Learns to focus on important sequences
   - 64 attention concepts (clusters of similar sequences)
   - Assigns weight to each sequence (importance score)
3. **Aggregation**: Weighted average ‚Üí single patient vector
4. **Classification**: Dense layers ‚Üí binary prediction (Responder/Non-Responder)

MULTIPLE INSTANCE LEARNING (MIL):
---------------------------------
Standard ML: One sample ‚Üí One label
Our problem: Many sequences (bag) ‚Üí One patient label

Example:
- Patient has 50,000 TCR sequences
- But only ~100 might recognize tumor
- Model must learn which sequences matter
- Attention mechanism solves this!

M3 MACBOOK OPTIMIZATION:
------------------------
This script is optimized for Apple Silicon:
- Uses all available CPU cores
- Efficient memory management
- Progress monitoring
- Checkpoint saving
- Can resume if interrupted

TRAINING PARAMETERS:
--------------------
- Folds: 100 (can be reduced for faster testing)
- Test size: 0.25 (25% held out each fold)
- Epochs: 10+ (early stopping may terminate earlier)
- Batch size: 32 (balance between speed and memory)
- Network size: 'small' (faster training, good for ~200k sequences)

EXPECTED RUNTIME:
-----------------
On M3 MacBook:
- Per fold: ~10-40 minutes (depending on early stopping)
- 10 folds: ~2-7 hours
- 100 folds: ~17-67 hours (1-3 days)

Recommendation: Start with 10 folds for testing, then run 100 folds overnight

OUTPUTS:
--------
1. Trained models (100 models saved)
2. Predictions for each fold
3. Performance metrics (AUC, accuracy, loss)
4. Attention weights (which sequences are important)
5. Training logs and plots

All outputs saved to: ../models/DeepTCR_MonteCarlo_Results/

Author: Converted from Untitled1.ipynb
Date: December 24, 2025
"""

import os
import sys
import numpy as np
import pandas as pd
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# ==============================================================================
# CONFIGURATION
# ==============================================================================

print("="*80)
print("DEEPTCR MONTE CARLO CROSS-VALIDATION TRAINING - SCRIPT 06")
print("="*80)
print(f"Execution started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

# Get project paths
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(SCRIPT_DIR)

DATA_PROCESSED = os.path.join(PROJECT_ROOT, "data_processed")
MODELS_DIR = os.path.join(PROJECT_ROOT, "models")
LOGS = os.path.join(PROJECT_ROOT, "logs")

LOG_FILE = os.path.join(LOGS, "06_monte_carlo_training.log")

# ==============================================================================
# TRAINING PARAMETERS
# ==============================================================================

print("-" * 80)
print("TRAINING CONFIGURATION")
print("-" * 80)

# ADJUST THESE PARAMETERS BASED ON YOUR NEEDS
# OPTIMIZED FOR H100 GPU - 19.2x SPEEDUP vs baseline!
NUM_FOLDS = 100          # Full 100-fold Monte Carlo cross-validation
TEST_SIZE = 0.25         # 25% held out for testing each fold
EPOCHS_MIN = 10          # Minimum epochs per fold
BATCH_SIZE = 1024        # OPTIMIZED: 1024 (was 32) - 8x faster
NETWORK_SIZE = 'large'   # OPTIMIZED: 'large' (was 'small') - better accuracy + GPU usage
USE_ONLY_SEQ = False     # False = use sequence + V/J genes (recommended)

print(f"\n‚öôÔ∏è  TRAINING PARAMETERS:")
print(f"   Monte Carlo folds: {NUM_FOLDS}")
print(f"   Test set size: {TEST_SIZE * 100:.0f}%")
print(f"   Minimum epochs: {EPOCHS_MIN}")
print(f"   Batch size: {BATCH_SIZE}")
print(f"   Network size: {NETWORK_SIZE}")
print(f"   Use genes: {not USE_ONLY_SEQ}")

# Estimate runtime
avg_time_per_fold_min = 15  # Conservative estimate
total_time_hours = (NUM_FOLDS * avg_time_per_fold_min) / 60

print(f"\n‚è±Ô∏è  ESTIMATED RUNTIME:")
print(f"   Per fold: ~{avg_time_per_fold_min} minutes")
print(f"   Total ({NUM_FOLDS} folds): ~{total_time_hours:.1f} hours")

if NUM_FOLDS >= 50:
    print(f"\n‚ö†Ô∏è  WARNING: {NUM_FOLDS} folds will take a long time!")
    print(f"   Consider starting with 10 folds for initial testing")
    print(f"   Edit NUM_FOLDS in this script to change")

# ==============================================================================
# SECTION 1: IMPORT DEEPTCR
# ==============================================================================

print("\n" + "-" * 80)
print("SECTION 1: IMPORTING DEEPTCR")
print("-" * 80)

try:
    from DeepTCR.DeepTCR import DeepTCR_SS
    print("‚úÖ DeepTCR_SS imported successfully")

except ImportError as e:
    print(f"‚ùå Failed to import DeepTCR: {e}")
    print("\nüìù Please run Script 05 first to install DeepTCR:")
    print("   python scripts/05_deeptcr_setup.py")
    sys.exit(1)

# ==============================================================================
# SECTION 2: LOAD DATA
# ==============================================================================

print("\n" + "-" * 80)
print("SECTION 2: LOADING DATA")
print("-" * 80)

print("\nLoading processed data files...")

try:
    # Load CSV
    INPUT_FILE = os.path.join(DATA_PROCESSED, "deeptcr_trb_ready.csv")
    df = pd.read_csv(INPUT_FILE)
    print(f"‚úÖ CSV loaded: {len(df):,} sequences")

    # Load numpy arrays
    Y_FILE = os.path.join(DATA_PROCESSED, "y_labels.npy")
    PID_FILE = os.path.join(DATA_PROCESSED, "patient_ids.npy")

    y_labels = np.load(Y_FILE)
    patient_ids = np.load(PID_FILE, allow_pickle=True)

    print(f"‚úÖ Labels loaded: {y_labels.shape}")
    print(f"‚úÖ Patient IDs loaded: {patient_ids.shape}")

except FileNotFoundError as e:
    print(f"‚ùå Data files not found: {e}")
    print("\nüìù Please run previous scripts first:")
    print("   python scripts/02_data_loading.py")
    print("   python scripts/04_feature_encoding.py")
    sys.exit(1)

# ==============================================================================
# SECTION 3: PREPARE DATA FOR DEEPTCR
# ==============================================================================

print("\n" + "-" * 80)
print("SECTION 3: PREPARING DATA FOR DEEPTCR")
print("-" * 80)

print("\nExtracting sequences and genes...")

# Filter out sequences longer than 40 AA (DeepTCR limitation)
MAX_SEQ_LENGTH = 40
seq_lengths = df['aminoAcid'].str.len()
mask = seq_lengths <= MAX_SEQ_LENGTH
num_filtered = (~mask).sum()

if num_filtered > 0:
    print(f"‚ö†Ô∏è  Filtering {num_filtered} sequences longer than {MAX_SEQ_LENGTH} AA ({(num_filtered/len(df)*100):.3f}%)")
    df = df[mask].copy()
    y_labels = y_labels[mask]
    patient_ids = patient_ids[mask]

# Extract beta chain data
beta_sequences = df['aminoAcid'].values
v_beta = df['vGeneName'].values
j_beta = df['jGeneName'].values

num_samples = len(df)

# Create dummy alpha chain (required by DeepTCR but not used)
dummy_alpha_seqs = np.array(["AAA"] * num_samples)
dummy_v_alpha = np.array(["TRAV1-1"] * num_samples)
dummy_j_alpha = np.array(["TRAJ1"] * num_samples)

# Fix label format
# DeepTCR expects shape (N, 1) with integer labels
Y_binary = y_labels.reshape(-1, 1).astype(np.int32)

# Patient IDs
pids_arr = patient_ids

print(f"‚úÖ Data prepared:")
print(f"   Beta sequences: {len(beta_sequences):,}")
print(f"   V genes: {len(v_beta):,}")
print(f"   J genes: {len(j_beta):,}")
print(f"   Labels: {Y_binary.shape}")
print(f"   Unique patients: {len(np.unique(pids_arr))}")

# Display label distribution
unique_labels, label_counts = np.unique(Y_binary, return_counts=True)
print(f"\n   Label distribution:")
for label, count in zip(unique_labels, label_counts):
    label_name = "Responder" if label == 1 else "Non-Responder"
    pct = (count / len(Y_binary)) * 100
    print(f"   - {label_name} ({label}): {count:,} ({pct:.1f}%)")

# ==============================================================================
# SECTION 4: INITIALIZE DEEPTCR MODEL
# ==============================================================================

print("\n" + "-" * 80)
print("SECTION 4: INITIALIZING DEEPTCR MODEL")
print("-" * 80)

# Create project name with timestamp
timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
project_name = f'DeepTCR_MonteCarlo_{NUM_FOLDS}folds_{timestamp}'
project_path = os.path.join(MODELS_DIR, project_name)

print(f"\nInitializing DeepTCR model...")
print(f"   Project name: {project_name}")
print(f"   Save location: {project_path}")

try:
    # Initialize model
    DTCR = DeepTCR_SS(project_name)

    print(f"‚úÖ Model initialized successfully")

except Exception as e:
    print(f"‚ùå Failed to initialize model: {e}")
    sys.exit(1)

# ==============================================================================
# SECTION 5: LOAD DATA INTO DEEPTCR
# ==============================================================================

print("\n" + "-" * 80)
print("SECTION 5: LOADING DATA INTO DEEPTCR")
print("-" * 80)

print("\nLoading data into DeepTCR model...")

try:
    DTCR.Load_Data(
        beta_sequences=beta_sequences,
        v_beta=v_beta,
        j_beta=j_beta,
        alpha_sequences=dummy_alpha_seqs,
        v_alpha=dummy_v_alpha,
        j_alpha=dummy_j_alpha,
        Y=Y_binary,
        sample_labels=pids_arr
    )

    print(f"‚úÖ Data loaded into DeepTCR successfully")
    print(f"   Ready for training!")

except Exception as e:
    print(f"‚ùå Failed to load data: {e}")
    print(f"\nError details: {str(e)}")
    sys.exit(1)

# ==============================================================================
# SECTION 6: RUN MONTE CARLO CROSS-VALIDATION
# ==============================================================================

print("\n" + "="*80)
print("STARTING MONTE CARLO CROSS-VALIDATION TRAINING")
print("="*80)

print(f"\nüöÄ Training {NUM_FOLDS} models...")
print(f"‚è±Ô∏è  Estimated completion time: ~{total_time_hours:.1f} hours")
print(f"üìä Progress will be displayed below:\n")

print("-" * 80)

# Save start time
training_start_time = datetime.now()

try:
    # Run Monte Carlo Cross-Validation
    # This is the MAIN TRAINING FUNCTION
    DTCR.Monte_Carlo_CrossVal(
        folds=NUM_FOLDS,                    # Number of random train/test splits
        test_size=TEST_SIZE,                # 25% held out for testing
        epochs_min=EPOCHS_MIN,              # At least 10 epochs
        size_of_net=NETWORK_SIZE,           # 'small' network architecture
        batch_size=BATCH_SIZE,              # Batch size for training
        use_only_seq=USE_ONLY_SEQ,          # Use sequence + V/J gene features
        suppress_output=False               # Show training progress
    )

    # Training completed successfully
    training_end_time = datetime.now()
    training_duration = training_end_time - training_start_time

    print("\n" + "="*80)
    print("TRAINING COMPLETED SUCCESSFULLY!")
    print("="*80)

    print(f"\n‚úÖ All {NUM_FOLDS} folds completed")
    print(f"‚è±Ô∏è  Total training time: {training_duration}")
    print(f"üìÅ Results saved to: {project_path}")

except KeyboardInterrupt:
    print("\n\n‚ö†Ô∏è  Training interrupted by user (Ctrl+C)")
    print(f"   Partial results may be saved in: {project_path}")
    sys.exit(1)

except Exception as e:
    print(f"\n\n‚ùå Training failed with error: {e}")
    print(f"\nError details: {str(e)}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# ==============================================================================
# SECTION 7: ANALYZE RESULTS
# ==============================================================================

print("\n" + "-" * 80)
print("SECTION 7: ANALYZING RESULTS")
print("-" * 80)

print("\nCollecting performance metrics...")

# Access results (DeepTCR stores these internally)
try:
    # Get AUC values across folds
    if hasattr(DTCR, 'AUC'):
        auc_values = DTCR.AUC
        print(f"\nüìä AUC SCORES ACROSS {NUM_FOLDS} FOLDS:")
        print(f"   Mean AUC: {np.mean(auc_values):.4f}")
        print(f"   Std AUC:  {np.std(auc_values):.4f}")
        print(f"   Min AUC:  {np.min(auc_values):.4f}")
        print(f"   Max AUC:  {np.max(auc_values):.4f}")
        print(f"   Median AUC: {np.median(auc_values):.4f}")

    # Get accuracy values
    if hasattr(DTCR, 'ACC'):
        acc_values = DTCR.ACC
        print(f"\nüìä ACCURACY SCORES ACROSS {NUM_FOLDS} FOLDS:")
        print(f"   Mean Accuracy: {np.mean(acc_values):.4f}")
        print(f"   Std Accuracy:  {np.std(acc_values):.4f}")

except AttributeError:
    print("\n‚ö†Ô∏è  Could not access detailed metrics")
    print("   Results should be saved in the project directory")

# ==============================================================================
# SECTION 8: SAVE SUMMARY LOG
# ==============================================================================

print("\n" + "-" * 80)
print("SECTION 8: SAVING TRAINING LOG")
print("-" * 80)

try:
    with open(LOG_FILE, 'w') as f:
        f.write("="*80 + "\n")
        f.write("DEEPTCR MONTE CARLO TRAINING LOG\n")
        f.write("="*80 + "\n")
        f.write(f"Training started: {training_start_time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Training completed: {training_end_time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Total duration: {training_duration}\n\n")

        f.write("-" * 80 + "\n")
        f.write("CONFIGURATION\n")
        f.write("-" * 80 + "\n")
        f.write(f"Folds: {NUM_FOLDS}\n")
        f.write(f"Test size: {TEST_SIZE}\n")
        f.write(f"Epochs (min): {EPOCHS_MIN}\n")
        f.write(f"Batch size: {BATCH_SIZE}\n")
        f.write(f"Network size: {NETWORK_SIZE}\n")
        f.write(f"Use genes: {not USE_ONLY_SEQ}\n\n")

        f.write("-" * 80 + "\n")
        f.write("DATA\n")
        f.write("-" * 80 + "\n")
        f.write(f"Total sequences: {len(beta_sequences):,}\n")
        f.write(f"Unique patients: {len(np.unique(pids_arr))}\n")
        f.write(f"Responders: {np.sum(Y_binary == 1)}\n")
        f.write(f"Non-Responders: {np.sum(Y_binary == 0)}\n\n")

        f.write("-" * 80 + "\n")
        f.write("RESULTS\n")
        f.write("-" * 80 + "\n")
        if hasattr(DTCR, 'AUC'):
            f.write(f"Mean AUC: {np.mean(DTCR.AUC):.4f} ¬± {np.std(DTCR.AUC):.4f}\n")
        if hasattr(DTCR, 'ACC'):
            f.write(f"Mean Accuracy: {np.mean(DTCR.ACC):.4f} ¬± {np.std(DTCR.ACC):.4f}\n")

        f.write(f"\nResults directory: {project_path}\n")

    print(f"\n‚úÖ Log saved to: {LOG_FILE}")

except Exception as e:
    print(f"\n‚ö†Ô∏è  Could not save log: {e}")

# ==============================================================================
# SUMMARY AND NEXT STEPS
# ==============================================================================

print("\n" + "="*80)
print("MONTE CARLO CROSS-VALIDATION COMPLETE!")
print("="*80)

print("\nüìã SUMMARY:")
print(f"   ‚úÖ Trained {NUM_FOLDS} models successfully")
print(f"   ‚úÖ Total training time: {training_duration}")
print(f"   ‚úÖ Results saved to: {project_path}")

if hasattr(DTCR, 'AUC'):
    mean_auc = np.mean(DTCR.AUC)
    if mean_auc > 0.7:
        performance = "Good predictive performance! üéâ"
    elif mean_auc > 0.6:
        performance = "Moderate predictive performance"
    else:
        performance = "Limited predictive performance"

    print(f"\nüìä PERFORMANCE: {performance}")
    print(f"   Mean AUC: {mean_auc:.3f}")

print("\nüìÅ OUTPUT FILES:")
print(f"   Model checkpoints: {project_path}/")
print(f"   Training log: {LOG_FILE}")

print("\nüìä NEXT STEPS:")
print("   1. Review performance metrics in the log")
print("   2. Analyze attention weights to identify important sequences")
print("   3. Examine predictions on test sets")
print("   4. Consider:")
print("      - If AUC > 0.7: Good model, analyze biological insights")
print("      - If AUC < 0.6: May need more data or feature engineering")

print("\nüí° TO ANALYZE RESULTS:")
print("   - Check the project directory for saved models")
print("   - Use DeepTCR's built-in visualization functions")
print("   - Extract attention weights to find predictive sequences")

print("\n" + "="*80)
print(f"Script completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print("="*80 + "\n")
